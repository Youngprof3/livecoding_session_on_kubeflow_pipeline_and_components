{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c43f1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python was not found; run without arguments to install from the Microsoft Store, or disable this shortcut from Settings > Manage App Execution Aliases.\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install --user --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d51b753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kfp in c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages (1.8.14)\n",
      "Requirement already satisfied: fire<1,>=0.3.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from kfp) (0.4.0)\n",
      "Requirement already satisfied: click<9,>=7.1.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from kfp) (7.1.2)\n",
      "Requirement already satisfied: protobuf<4,>=3.13.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from kfp) (3.20.0)\n",
      "Requirement already satisfied: uritemplate<4,>=3.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from kfp) (3.0.1)\n",
      "Requirement already satisfied: tabulate<1,>=0.8.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from kfp) (0.8.10)\n",
      "Requirement already satisfied: Deprecated<2,>=1.2.7 in c:\\users\\user\\anaconda3\\lib\\site-packages (from kfp) (1.2.13)\n",
      "Requirement already satisfied: typer<1.0,>=0.3.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from kfp) (0.6.1)\n",
      "Requirement already satisfied: docstring-parser<1,>=0.7.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from kfp) (0.14.1)\n",
      "Requirement already satisfied: cloudpickle<3,>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from kfp) (2.1.0)\n",
      "Requirement already satisfied: strip-hints<1,>=0.1.8 in c:\\users\\user\\anaconda3\\lib\\site-packages (from kfp) (0.1.10)\n",
      "Requirement already satisfied: kfp-pipeline-spec<0.2.0,>=0.1.16 in c:\\users\\user\\anaconda3\\lib\\site-packages (from kfp) (0.1.16)\n",
      "Requirement already satisfied: PyYAML<6,>=5.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from kfp) (5.4.1)\n",
      "Requirement already satisfied: requests-toolbelt<1,>=0.8.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from kfp) (0.9.1)\n",
      "Requirement already satisfied: absl-py<2,>=0.9 in c:\\users\\user\\anaconda3\\lib\\site-packages (from kfp) (1.0.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from kfp) (2.8.2)\n",
      "Requirement already satisfied: pydantic<2,>=1.8.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from kfp) (1.9.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from kfp) (1.35.0)\n",
      "Requirement already satisfied: kubernetes<19,>=8.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from kfp) (18.20.0)\n",
      "Requirement already satisfied: kfp-server-api<2.0.0,>=1.1.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from kfp) (1.8.4)\n",
      "Requirement already satisfied: google-cloud-storage<2,>=1.20.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from kfp) (1.44.0)\n",
      "Requirement already satisfied: google-api-python-client<2,>=1.7.8 in c:\\users\\user\\anaconda3\\lib\\site-packages (from kfp) (1.12.11)\n",
      "Requirement already satisfied: typing-extensions<5,>=3.7.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from kfp) (4.3.0)\n",
      "Requirement already satisfied: jsonschema<4,>=3.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from kfp) (3.2.0)\n",
      "Requirement already satisfied: six in c:\\users\\user\\anaconda3\\lib\\site-packages (from absl-py<2,>=0.9->kfp) (1.15.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\user\\anaconda3\\lib\\site-packages (from Deprecated<2,>=1.2.7->kfp) (1.12.1)\n",
      "Requirement already satisfied: termcolor in c:\\users\\user\\anaconda3\\lib\\site-packages (from fire<1,>=0.3.1->kfp) (1.1.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp) (2.28.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp) (1.56.4)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.15.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-api-python-client<2,>=1.7.8->kfp) (0.20.4)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.0.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-api-python-client<2,>=1.7.8->kfp) (0.1.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.1->kfp) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.1->kfp) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.1->kfp) (0.2.8)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.1->kfp) (52.0.0.post20210125)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=1.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-cloud-storage<2,>=1.20.0->kfp) (2.3.3)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=1.6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-cloud-storage<2,>=1.20.0->kfp) (2.3.2)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-resumable-media<3.0dev,>=1.3.0->google-cloud-storage<2,>=1.20.0->kfp) (1.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from httplib2<1dev,>=0.15.0->google-api-python-client<2,>=1.7.8->kfp) (2.4.7)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jsonschema<4,>=3.0.1->kfp) (0.17.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jsonschema<4,>=3.0.1->kfp) (20.3.0)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\user\\anaconda3\\lib\\site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp) (2.8.1)\n",
      "Requirement already satisfied: urllib3>=1.15 in c:\\users\\user\\anaconda3\\lib\\site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp) (1.26.4)\n",
      "Requirement already satisfied: certifi in c:\\users\\user\\anaconda3\\lib\\site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp) (2020.12.5)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from kubernetes<19,>=8.0.0->kfp) (1.3.3)\n",
      "Requirement already satisfied: requests-oauthlib in c:\\users\\user\\anaconda3\\lib\\site-packages (from kubernetes<19,>=8.0.0->kfp) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.1->kfp) (0.4.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp) (2.10)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp) (2.1.0)\n",
      "Requirement already satisfied: wheel in c:\\users\\user\\anaconda3\\lib\\site-packages (from strip-hints<1,>=0.1.8->kfp) (0.36.2)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests-oauthlib->kubernetes<19,>=8.0.0->kfp) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install kfp --upgrade --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5267dbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "from kfp import dsl\n",
    "import kfp.components as comp\n",
    "from kfp.components import InputPath, OutputPath\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f65adf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir ='/Users/user/Documents/kubeflow/kubeflow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "561b8d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the content of the data loading script\n",
    "\n",
    "def data_loading(data_path):\n",
    "    '''\n",
    "    Function for loading diabetes dataset\n",
    "    '''\n",
    "     \n",
    "    import os\n",
    "    import argparse\n",
    "    import pandas as pd\n",
    "    import pickle\n",
    "    #reading the data from its source\n",
    "    data = pd.read_csv(\"https://raw.githubusercontent.com/Youngprof3/kubeflow_test/main/project_on_diabetes_kubeflow/data_loading/dataset.csv\")\n",
    "     #Save the data as a pickle file to be used by the preprocess component.\n",
    "    with open(f'{data_path}/working_data.pkl', 'wb') as f:\n",
    "        pickle.dump(data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19b3de86",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loading(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b77cb2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the content of the data preprocessing script\n",
    "\n",
    "\n",
    "\n",
    "def data_preprocessing(data_path):\n",
    "    \n",
    "    import pandas as pd\n",
    "    import argparse\n",
    "    import numpy as np\n",
    "    import pickle\n",
    "    from sklearn.preprocessing import MinMaxScaler, Normalizer\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    \n",
    "    with open(f'{data_path}/working_data.pkl', 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        #data features\n",
    "        X = data.iloc[:,:-1]\n",
    "        #target data\n",
    "        y = data.iloc[:,-1:]\n",
    "        #encoding the categorical columns\n",
    "        le = LabelEncoder()\n",
    "\n",
    "        X['gender'] = le.fit_transform(X['gender'])\n",
    "        y['class'] = le.fit_transform(y['class'])\n",
    "\n",
    "        #splitting the data\n",
    "        X_train,X_test,y_train,y_test = train_test_split( X,y, test_size=0.3, random_state = 42)\n",
    "        #feature scaling\n",
    "        ms =MinMaxScaler(feature_range=(0,1))\n",
    "        X_train = ms.fit_transform(X_train)\n",
    "        X_test = ms.transform(X_test)\n",
    "\n",
    "        #Save the train_data as a pickle file to be used by the train component.\n",
    "        with open(f'{data_path}/train_data.pkl', 'wb') as f:\n",
    "            pickle.dump((X_train,  y_train), f)\n",
    "\n",
    "        #Save the test_data as a pickle file to be used by the predict component.\n",
    "        with open(f'{data_path}/test_data.pkl', 'wb') as f:\n",
    "            pickle.dump((X_test,  y_test), f)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca18eb72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.3)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    }
   ],
   "source": [
    "data_preprocessing(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a15cede4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the content of the model training script\n",
    "\n",
    "\n",
    "def model_training(data_path):\n",
    "    \n",
    "    import numpy as np\n",
    "    import pickle\n",
    "    import argparse\n",
    "    import os\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "    #loading the train data\n",
    "    with open(f'{data_path}/train_data.pkl', 'rb') as f:\n",
    "        train_data = pickle.load(f)\n",
    "    #Separate the X_train from y_train.\n",
    "        X_train, y_train = train_data\n",
    "\n",
    "        log_regres = LogisticRegression(max_iter=10000)\n",
    "        lr_model = log_regres.fit(X_train, y_train)\n",
    "\n",
    "        svm = SVC(kernel =\"linear\", random_state=2)\n",
    "        svm_model = svm.fit(X_train, y_train)\n",
    "\n",
    "        knn = KNeighborsClassifier(n_neighbors=7)\n",
    "        knn_model = knn.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    with open(f'{data_path}/lr_model.pkl', 'wb') as f:\n",
    "        pickle.dump(lr_model, f)\n",
    "    \n",
    "    with open(f'{data_path}/svm_model.pkl', 'wb') as f:\n",
    "        pickle.dump(svm_model, f)\n",
    "    \n",
    "    with open(f'{data_path}/knn_model.pkl', 'wb') as f:\n",
    "        pickle.dump(knn_model, f)\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8c11e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "<ipython-input-10-653d7a35729f>:27: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  knn_model = knn.fit(X_train, y_train)\n"
     ]
    }
   ],
   "source": [
    "model_training(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "493f48c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the content of the model testing script\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def model_testing(data_path):\n",
    "    \n",
    "    import numpy as np\n",
    "    import pickle\n",
    "    import argparse\n",
    "    import os\n",
    "    #loading the test data\n",
    "    \n",
    "    with open(f'{data_path}/test_data.pkl', 'rb') as f:\n",
    "        test_data = pickle.load(f)\n",
    "    \n",
    "    #Separate the X_test from y_test.\n",
    "        X_test, y_test = test_data\n",
    "\n",
    "    with open(f'{data_path}/lr_model.pkl', 'rb') as f:\n",
    "        log_reg_model = pickle.load(f)\n",
    "    \n",
    "    with open(f'{data_path}/svm_model.pkl', 'rb') as f:\n",
    "        svm_clas_model = pickle.load(f)\n",
    "        \n",
    "    with open(f'{data_path}/knn_model.pkl', 'rb') as f:\n",
    "        knn_clas_model = pickle.load(f)\n",
    "        \n",
    "    \n",
    "\n",
    "    y_pred_lr = log_reg_model.predict(X_test)\n",
    "    y_pred_svm = svm_clas_model.predict(X_test)\n",
    "    y_pred_knn = knn_clas_model.predict(X_test)\n",
    "\n",
    "    \n",
    "    with open(f'{data_path}/y_pred_lr.pkl', 'wb') as f:\n",
    "        pickle.dump(y_pred_lr, f)\n",
    "        \n",
    "    with open(f'{data_path}/y_pred_svm.pkl', 'wb') as f:\n",
    "        pickle.dump(y_pred_svm, f)\n",
    "        \n",
    "    with open(f'{data_path}/y_pred_knn.pkl', 'wb') as f:\n",
    "        pickle.dump(y_pred_knn, f)\n",
    "        \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22bfd04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_testing(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2e271ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the content of the model evaluation script\n",
    "\n",
    "\n",
    "\n",
    "def model_evaluation(data_path):\n",
    "    \n",
    "    import numpy as np\n",
    "    import pickle\n",
    "    from sklearn.metrics import classification_report, confusion_matrix\n",
    "    #loading the test data\n",
    "    with open(f'{data_path}/test_data.pkl', 'rb') as f:\n",
    "        test_data = pickle.load(f)\n",
    "    #Separate the X_test from y_test.\n",
    "        X_test, y_test = test_data\n",
    "\n",
    "    with open(f'{data_path}/y_pred_lr.pkl', 'rb') as f:\n",
    "         y_pred_lr = pickle.load(f)\n",
    "            \n",
    "    with open(f'{data_path}/y_pred_svm.pkl', 'rb') as f:\n",
    "         y_pred_svm = pickle.load(f)\n",
    "            \n",
    "    with open(f'{data_path}/y_pred_knn.pkl', 'rb') as f:\n",
    "         y_pred_knn = pickle.load(f)\n",
    "    \n",
    "\n",
    "\n",
    "    class_report_lr = classification_report(y_test, y_pred_lr)\n",
    "    class_report_svm = classification_report(y_test, y_pred_svm)\n",
    "    class_report_knn = classification_report(y_test, y_pred_knn)\n",
    "\n",
    "\n",
    "    print(f'Classification report for the logistic regression model: {class_report_lr}')\n",
    "\n",
    "    print(f'Classification report for the support vector machine model: {class_report_svm}')\n",
    "\n",
    "    print(f'Classification report for the k-nearest neighbor model: {class_report_knn}')\n",
    "\n",
    "\n",
    "    confusion_matrix_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "    confusion_matrix_svm = confusion_matrix(y_test, y_pred_svm)\n",
    "    confusion_matrix_knn = confusion_matrix(y_test, y_pred_knn)\n",
    "\n",
    "    print(f'Confusion matrix for the logistic regression model: {confusion_matrix_lr}')\n",
    "\n",
    "    print(f'Confusion matrix for the support vector machine model: {confusion_matrix_svm}')\n",
    "\n",
    "    print(f'Confusion matrix for the k-nearest neighbor model: {confusion_matrix_knn}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea47be47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for the logistic regression model:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.95        36\n",
      "           2       1.00      0.10      0.18        10\n",
      "           3       0.97      1.00      0.98       253\n",
      "           4       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.96       300\n",
      "   macro avg       0.72      0.52      0.53       300\n",
      "weighted avg       0.96      0.96      0.95       300\n",
      "\n",
      "Classification report for the support vector machine model:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.94        36\n",
      "           2       0.67      0.20      0.31        10\n",
      "           3       0.98      1.00      0.99       253\n",
      "           4       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.97       300\n",
      "   macro avg       0.63      0.55      0.56       300\n",
      "weighted avg       0.96      0.97      0.96       300\n",
      "\n",
      "Classification report for the k-nearest neighbor model:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81        36\n",
      "           2       0.25      0.30      0.27        10\n",
      "           3       0.98      0.98      0.98       253\n",
      "           4       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.93       300\n",
      "   macro avg       0.51      0.52      0.52       300\n",
      "weighted avg       0.93      0.93      0.93       300\n",
      "\n",
      "Confusion matrix for the logistic regression model: [[ 35   0   1   0]\n",
      " [  2   1   7   0]\n",
      " [  1   0 252   0]\n",
      " [  0   0   1   0]]\n",
      "Confusion matrix for the support vector machine model: [[ 36   0   0   0]\n",
      " [  5   2   3   0]\n",
      " [  0   1 252   0]\n",
      " [  0   0   1   0]]\n",
      "Confusion matrix for the k-nearest neighbor model: [[ 29   6   1   0]\n",
      " [  5   3   2   0]\n",
      " [  2   3 248   0]\n",
      " [  0   0   1   0]]\n"
     ]
    }
   ],
   "source": [
    "model_evaluation(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4adc222",
   "metadata": {},
   "outputs": [],
   "source": [
    "obtain_data_op = kfp.components.create_component_from_func(data_loading, base_image=\"python:3.10.4-slim-buster\" ,packages_to_install=['pandas'])\n",
    "\n",
    "preprocess_op = kfp.components.create_component_from_func(data_preprocessing, base_image=\"python:3.10.4-slim-buster\"  ,packages_to_install=['pandas','sklearn'])\n",
    "\n",
    "model_train_op = kfp.components.create_component_from_func(model_training, base_image=\"python:3.10.4-slim-buster\"  ,packages_to_install=['pandas', 'sklearn'])\n",
    "\n",
    "model_test_op = kfp.components.create_component_from_func(model_testing, base_image=\"python:3.10.4-slim-buster\" ,packages_to_install=['pandas', 'sklearn'] )\n",
    "\n",
    "model_evaluation_op = kfp.components.create_component_from_func(model_evaluation, base_image=\"python:3.10.4-slim-buster\" ,packages_to_install=['pandas', 'sklearn'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5b230eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/Users/user/Documents/code/lightweight_component'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5aefe3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(name=\"Dibetes Pipeline Lightweight\", description=\"Performs preprocessing, training, testing and prediction if a patient is diabetic or not\")\n",
    "\n",
    "def diabetic_prediction():\n",
    "    pvc_op = dsl.VolumeOp(name='Persistent Volume Claim', \n",
    "                resource_name='data-volume',\n",
    "                size='2Gi',\n",
    "                modes=dsl.VOLUME_MODE_RWO)\n",
    "\n",
    "     #create obtain data component\n",
    "    \n",
    "    obtain_data_task = obtain_data_op(data_path).add_pvolumes({data_path: pvc_op.volume})\n",
    "    # Create preprocess components.\n",
    "   \n",
    "    preprocess_task = preprocess_op(data_path).add_pvolumes({data_path: pvc_op.volume}).after(obtain_data_task)\n",
    "    # Create train component.\n",
    "    \n",
    "    model_train_task = model_train_op(data_path).add_pvolumes({data_path: pvc_op.volume}).after(preprocess_task)\n",
    "    # Create test component.\n",
    "    \n",
    "    model_test_task = model_test_op(data_path).add_pvolumes({data_path: pvc_op.volume}).after(model_train_task)\n",
    "    # Create evaluation component.\n",
    "    \n",
    "    model_evaluation_task = model_evaluation_op(data_path).add_pvolumes({data_path: pvc_op.volume}).after(model_test_task)\n",
    "\n",
    "    \n",
    "\n",
    "kfp.compiler.Compiler().compile(diabetic_prediction, 'diabetic_prediction_pvc.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b88354c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c62bac3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
